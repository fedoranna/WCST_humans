---
title: "WCST data analysis - Step 2"
output:
  word_document: default
  html_document: default
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r Setup and parameters, include=FALSE}

# Packages
library(knitr)
library(dplyr)
library(stringdist)
library(reshape2)   
library(ggplot2)
library(openxlsx)

knitr::opts_chunk$set(echo = FALSE)

# Parameters
rm(list = ls()) # clear workspace
datadir = "C:/Users/fedor/OneDrive/Documents/R/WCST_humans/RESULTS/Round1/" # the directory of the data files from Step 1
datafile = "_Step1_output.RData"
rated_data = "_free_text_answers_agreed.xlsx"
samplesize = 78 # sample size per group

```

# Manipulate data

## Read data frames and manually rated data

We have loaded data frames saved by the Step 1 script, and merged the manually categorized free text answers about the rule with participantdata_inc.

```{r Read data}

# Load data
load(paste(datadir, datafile, sep=""))
rates <- read.xlsx(paste(datadir, rated_data, sep=""))

r6 = match(participantdata_inc$index, rates$index)
participantdata_inc$rule_code <- rates$agreed.rule[r6]
participantdata_inc$numbers4letters <- rates$Letter.rule.expained.with.numbers


```

## Exclude participants

We excluded extra participants if there were more than 78 in a condition.

```{r Exclude participants}

WLIN <- filter(participantdata_inc, condition=="wlin")[1:samplesize,]
WLOUT <- filter(participantdata_inc, condition=="wlout")[1:samplesize,]
WNOL <- filter(participantdata_inc, condition=="wnol")[1:samplesize,]
WNOLFS <- filter(participantdata_inc, condition=="wnolfs")[1:samplesize,]
WNOLA <- filter(participantdata_inc, condition=="wnola")[1:samplesize,]
MOONSQ <- filter(participantdata_inc, condition=="moonsq")[1:samplesize,]
WONLY <- filter(participantdata_inc, condition=="wonly")[1:samplesize,]

participantdata_inc <- rbind(WLIN, WLOUT, WNOL, WNOLFS, WNOLA, MOONSQ, WONLY)

```

## Modify data

Diffifulty of taks was supposed to be a number 1-10, but it was also a free text answer, and some participants went outside the recommended range (e.g.: difficulty = 50). We capped these numbers to 10.

```{r Modify}

participantdata_inc$difficulty_modified <- ifelse(participantdata_inc$difficulty<1, 1, participantdata_inc$difficulty)
participantdata_inc$difficulty_modified <- ifelse(participantdata_inc$difficulty_modified>10, 10, participantdata_inc$difficulty)

```

# Descriptive statistics

```{r Conditions}

partic_groups <- participantdata_inc %>%
  group_by(condition) %>%
  summarize(
    Nbof_participants = n_distinct(index),
    Nbof_solvers = sum(solver),
    Nbof_nonsolvers = Nbof_participants - Nbof_solvers,
    Failure_rate = Nbof_nonsolvers / Nbof_participants,
    Solution_rate = Nbof_solvers/Nbof_participants,
    Nbof_ahas = sum(aha),
    Aha_rate = Nbof_ahas/Nbof_participants,
    Nbof_ahas_solvers = sum(solver*aha),
    Aha_rate_solvers = Nbof_ahas_solvers / Nbof_solvers,
    Avg_task_time = mean(task_time),
    Avg_nbof_moves = mean(nbof_moves)
  )


partic_groups <- arrange(partic_groups, factor(condition, levels = c("wlin", "wlout", "wnol", "wnolfs", "wnola", "moonsq", "wonly")))

conditions <- c("LettersIn", "LettersOut", "NoLetters", "FixedSequence", "AmbiguousCards", "Moon", "LettersOnly")
partic_groups2 <- tibble::column_to_rownames(partic_groups, "condition") # same data, but rownames=conditions
partic_groups[,1] <- conditions

kable(partic_groups[,c(1, 2, 10, 5, 11, 12)], 
      digits = 3,
      col.names = c("Condition", "Number of participants", "Aha rate of solvers", "Failure rate", "Avg task time", "Avg number of moves"))
```

# Statistical data analysis: Experiment 1

## Difficulty of the task

We compared the difficulty of the task in different conditions  

* first by a Fisher’s exact test on the number of solvers
* if the Fisher’s exact test test is not significant, we will compare task time, because it is possible that the number of solvers does not differ in the two conditions but still, if task time is significantly lower in one of the conditions that means that those who solved it, solved it faster. For comparing task time, we will use ANOVA if the data is normally distributed, or a two-sample Wilcoxon test (same as the Mann-Whitney test) if it is not.


### Solution rate

We analyzed the contingency table containing the number of solvers and non-solvers in pairs of conditions. A p<0.05 means that the row/column association is statistically significant. 

Experiment 1: WLIN < WLOUT < WNOL

```{r Solution rates}

barplot(partic_groups$Solution_rate, names.arg = partic_groups$condition, main="Solution rates")

F1 <- fisher.test(partic_groups2[c("wlin","wlout"), c("Nbof_solvers","Nbof_nonsolvers")])
F2 <- fisher.test(partic_groups2[c("wlout","wnol"), c("Nbof_solvers","Nbof_nonsolvers")])

```

WLIN-WLOUT: p = `r F1$p.value`   
WLOUT-WNOL: p = `r F2$p.value`

### Solution time

We checked whether the data was normally distributed with Kolmogorov-Smirnoff test:

```{r Solution time}

hist(participantdata_inc$task_time)
boxplot(task_time ~ condition, 
        participantdata_inc,
        ylab="Task time")

if (F1$p.value > 0.05){
  
  # normality_wlin <- ks.test(
  #   participantdata_inc %>% filter(condition=="wlin") %>% select(task_time),
  #   pnorm, alternative="two.sided", exact=NULL)
  # normality_wlout <- ks.test(
  #   participantdata_inc %>% filter(condition=="wlout") %>% select(task_time),
  #   pnorm, alternative="two.sided", exact=NULL)

  wlin_time <- participantdata_inc %>% filter(condition=="wlin") %>% select(task_time)
  wlin_time <- matrix(wlin_time[,1])
  
  wlout_time <- participantdata_inc %>% filter(condition=="wlout") %>% select(task_time)
  wlout_time <- matrix(wlout_time[,1])
  
  W1 <- wilcox.test(wlin_time, wlout_time,
            alternative = "two.sided", 
            mu = 0, paired = FALSE, exact = NULL, correct = TRUE,
            conf.int = FALSE, conf.level = 0.95)

}

if (F2$p.value > 0.05){
  
  wlin_time <- participantdata_inc %>% filter(condition=="wlin") %>% select(task_time)
  wlin_time <- matrix(wlin_time[,1])

  wlout_time <- participantdata_inc2 %>% filter(condition=="wlout") %>% select(task_time)
  wlout_time <- matrix(wlout_time[,1])

  normality_wlout <- ks.test(
    participantdata_inc %>% filter(condition=="wlout") %>% select(task_time),
    pnorm, alternative="two.sided", exact=NULL)
  normality_wnol <- ks.test(
    participantdata_inc %>% filter(condition=="wnol") %>% select(task_time),
    pnorm, alternative="two.sided", exact=NULL)

}


# ANOVA with greenhouse-geisser correction: robust also for non-normally distributed data

```


### Binary logistic regression



## Aha feelings: Fisher's exact test

```{r Aha-ratings}

barplot(partic_groups$Aha_rate_solvers, names.arg = partic_groups$condition, main="Aha rate of solvers")

# Experiment 1 vs control
# WLIN > WONLY
# WLOUT > WONLY
# WNOL > WONLY

# Experiment 1 levels
# WLOUT > WLIN
# WNOL > WLOUT

# Experiment 2 vs control
# WNOLFS > WONLY
# WNOLA > WONLY
# MOONSQ > WONLY




```

# Statistical data analysis: Experiment 2

MOONSQ < WNOLA: Removing distracting visual cues makes finding the sequence rule easier
WNOLFS <  WNOLA: The sequence rule can be used in both conditions but the exclusion rule can only be used in the WNOLFS condition, which might help. 


```{r Solution rates - Experiment 2}

barplot(partic_groups$Solution_rate, names.arg = partic_groups$condition, main="Solution rates")

fisher.test(partic_groups2[c("wnolfs","wnola"), c("Nbof_solvers","Nbof_nonsolvers")])
fisher.test(partic_groups2[c("moonsq","wnola"), c("Nbof_solvers","Nbof_nonsolvers")])

```


## Other

### Language

```{Language}

filter(participantdata_inc, participantdata_inc$numbers4letters == 1)

```

### Restructuring

Sliding average for move time

### Rules used



