---
title: "WCST data analysis - Step 2"
output:
  word_document: default
  html_document: default
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r Setup and parameters, include=FALSE}

# Packages
library(knitr)
library(dplyr)
library(stringdist)
library(reshape2)   
library(ggplot2)
library(openxlsx)
library(pander)

knitr::opts_chunk$set(echo = FALSE)

# Parameters
rm(list = ls()) # clear workspace
datadir = "C:/Users/fedor/OneDrive/Documents/R/WCST_humans/RESULTS/Experiments/" # the directory of the data files from Step 1
datafile = "_Step1_output.RData"
rated_data = "C:/Users/fedor/OneDrive/Documents/R/WCST_humans/RESULTS/Experiments/_free_text_answers_agreed.xlsx"

```

# Manipulate data

## Read data frames and manually rated data

We have loaded data frames saved by the Step 1 script, and merged the manually categorized free text answers about the rule with participantdata_inc.

```{r Read data}

# Load data
load(paste(datadir, datafile, sep=""))
rates <- read.xlsx(rated_data)

r6 = match(participantdata_inc$index, rates$index)
participantdata_inc$rule_code <- rates$agreed.rule[r6]
participantdata_inc$numbers4letters <- rates$Letter.rule.expained.with.numbers[r6]

```

## Modify data

The subjective difficulty rating was supposed to be a number between 1-10, but it was a free text answer, and some participants went outside the recommended range (e.g.: difficulty = 50). We replaced these numbers with NA, because we were not sure whether participants wanted to indicate that the task was very difficult or if they mistakenly applied a range between 1-100 (some of them solved the task relatively quickly).

```{r Modify}

participantdata_inc$difficulty_modified <- ifelse(participantdata_inc$difficulty<1, NA, participantdata_inc$difficulty)
participantdata_inc$difficulty_modified <- ifelse(participantdata_inc$difficulty>10, NA, participantdata_inc$difficulty)

```

# Descriptive statistics

## Conditions

The number of participants was 78 in each condition. 

```{r Conditions}

partic_groups <- participantdata_inc %>%
  group_by(condition) %>%
  summarize(
    Nbof_participants = n_distinct(index),
    Nbof_solvers = sum(solver),
    Nbof_nonsolvers = Nbof_participants - Nbof_solvers,
    Failure_rate = Nbof_nonsolvers / Nbof_participants,
    Solution_rate = Nbof_solvers/Nbof_participants,
    Nbof_ahas = sum(aha),
    Aha_rate = Nbof_ahas/Nbof_participants,
    Nbof_ahas_solvers = sum(solver*aha),
    Nbof_noahas_solvers = Nbof_solvers - Nbof_ahas_solvers,
    Aha_rate_solvers = Nbof_ahas_solvers / Nbof_solvers,
    Median_task_time = median(task_time),
    SD_task_time = sd(task_time),
    Avg_nbof_moves = mean(nbof_moves)
  )
partic_groups <- arrange(partic_groups, factor(condition, levels = c("wlin", "wlout", "wnol", "wonly", "wnolfs", "wnola", "moonsq")))

conditions <- c("Letters In", "Letters Out", "No Letters", "Letters Only", "Fixed Deck", "Ambiguous Cards", "Uniform Deck")
partic_groups2 <- tibble::column_to_rownames(partic_groups, "condition") # same data, but rownames=conditions
partic_groups[,1] <- conditions

kable(partic_groups[,c(1, 2, 3, 6, 12, 13, 11)], 
      digits = 2,
      col.names = c("Condition", "Number of participants", "Number of solvers", "Solution rate", "Median task time (min)", "SD of task time", "Aha rate of solvers"))
```

## Demographics

```{r Demographics}

participantdata_E1 <- filter(participantdata_inc, 
                             condition=="wlin" | condition=="wlout" | condition=="wnol" | condition=="wonly")
participantdata_E2 <- filter(participantdata_inc, 
                             condition=="wnlofs" | condition=="wnola" | condition=="moonsq")

```

In Experiment 1, out of `r nrow(participantdata_E1)` participants, `r nrow(filter(participantdata_E1, manual_sex == "female"))` were female. The majority were United Kingdom nationals (`r nrow(filter(participantdata_E1, nationality == "United Kingdom"))` participants).  
In Experiment 2, out of `r nrow(participantdata_E2)` participants, `r nrow(filter(participantdata_E2, manual_sex == "female"))` were female. The majority were United Kingdom nationals (`r nrow(filter(participantdata_E2, nationality == "United Kingdom"))` participants).


# Statistical tests

## Difficulty of the task

A task is more difficult in one condition than in another condition, if less participants are able to solve it, or if it takes longer for participants to solve it (even if solution rates are the same). This is why, we compared the difficulty of the task

* first, by Fisher’s exact test on the number of solvers (pairwise comparisons)
* then, if the Fisher’s exact test was not significant, we compared task time by two-sample Wilcoxon test (same as the Mann-Whitney test)
* **ANOVA with Greenhouse-Geisser correction: robust also for non-normally distributed data**
* **We also used binary logistic regression.**

The following plots compare all conditions of Experiment 1 and 2 and the control condition:  

* The barplot shows solution rates accross conditions.
* The histogram shows the distribution of task time in all the conditions.
* The boxplot shows the distribution of task time accrosss condition. Circles represent outliers. Whiskers extend to the most extreme data point which is no more than 1.5 times the interquartile range from the box. If the notches of two boxes do not overlap this is strong evidence that the two medians differ.


```{r Plots for task difficulty, warning=FALSE}

par(mar=c(8,4,4,4))
barplot(partic_groups$Solution_rate, 
        names.arg = conditions,
        ylab = "Solution rate", 
        ylim = c(0,1),
        cex.names=0.9,
        las=2)

boxplot(task_time ~ condition, participantdata_inc,
        ylab="Task time",
        xlab="",
        range=1.5,
        names=conditions,
        notch=FALSE,
        cex.names=0.2,
        las=3,
        cex.axis=0.8)

par(mar=c(4,4,4,4))
hist(participantdata_inc$task_time,
     xlab="Task time (min)",
     main="")

# Kolmogorov-Smirnov Test on task_time (all conditions)
normality <- ks.test(
   participantdata_inc %>% select(task_time),
   pnorm, alternative="two.sided", exact=NULL)

```

The histogram of task times shows that the data is not normally distributed, so we had to use nonparametric tests. The Kolmogorov-Smirnov normality test on task time also showed that the data was not normally distributed.

`r pander(normality)`


## Aha feelings

We used Fisher's exact tests to make pairwise comparison between conditions regarding the Aha-feelings of solvers (whether they reported having aha-feelings or not).

```{r Plot for Aha}

par(mar=c(8,4,4,4))
barplot(partic_groups$Aha_rate_solvers, 
        names.arg = conditions, 
        ylab="Aha rate of solvers",
        ylim=c(0,1),
        cex.names=0.9,
        las=2)

```

# Results - Experiment 1

## Difficulty of the task - Experiment 1

```{r Solution rates}

F1 <- fisher.test(partic_groups2[c("wlin","wlout"), c("Nbof_solvers","Nbof_nonsolvers")])
F2 <- fisher.test(partic_groups2[c("wlout","wnol"), c("Nbof_solvers","Nbof_nonsolvers")])

```

We analyzed the contingency table containing the number of solvers and non-solvers in pairs of conditions with Fisher's exact test. A p<0.05 means that the row/column association is statistically significant:

WLIN-WLOUT: **not significant** 
`r pander(F1)`   
  
WLOUT-WNOL: **significant** 
`r pander(F2)`

```{r Solution times}

# Two-sample Wilcoxon test

wlin_time <- participantdata_inc %>% filter(condition=="wlin") %>% select(task_time)
wlin_time <- matrix(wlin_time[,1])

wlout_time <- participantdata_inc %>% filter(condition=="wlout") %>% select(task_time)
wlout_time <- matrix(wlout_time[,1])

W1 <- wilcox.test(wlin_time, wlout_time,
                  alternative = "two.sided", 
                  mu = 0, paired = FALSE, exact = NULL, correct = TRUE,
                  conf.int = FALSE, conf.level = 0.95)

# ANOVA with Greenhouse-Geisser correction


# Binary logistic regression



```

WLIN-WLOUT task times: **significant**  
`r pander(W1)`

We conclude, that the difficulty of conditions in Experiment 1 was:  

* WLIN < WLOUT
* WLOUT < WNOL

## Aha feelings - Experiment 1

```{r Aha feelings}

# Experiment 1 vs control:

F3 <- fisher.test(partic_groups2[c("wlin","wonly"), c("Nbof_ahas_solvers","Nbof_noahas_solvers")])
F4 <- fisher.test(partic_groups2[c("wlout","wonly"), c("Nbof_ahas_solvers","Nbof_noahas_solvers")])
F5 <- fisher.test(partic_groups2[c("wnol","wonly"), c("Nbof_ahas_solvers","Nbof_noahas_solvers")])

# Experiment 1 levels:

F6 <- fisher.test(partic_groups2[c("wlout","wlin"), c("Nbof_ahas_solvers","Nbof_noahas_solvers")])
F7 <- fisher.test(partic_groups2[c("wnol","wlout"), c("Nbof_ahas_solvers","Nbof_noahas_solvers")])

```

We analyzed the contingency table containing the number of solvers who reported Aha-feelings and number of solvers who did not report Aha-feelings in pairs of conditions with Fisher's exact tests. We compared all conditions to the control condition (Letters Only). A p<0.05 means that the row/column association is statistically significant:

WLIN > WONLY: **significant**  
`r pander(F3)`  

WLOUT > WONLY: **significant**    
`r pander(F4)`  

WNOL > WONLY: **significant**    
`r pander(F5)`  

Levels:

WLOUT > WLIN: **not significant**  
`r pander(F6)`  

WNOL > WLOUT: **not significant**  
`r pander(F7)`

## Described rules - Experiment 1

```{r Deescribed rules - Experiment 1}



```


# Results - Experiment 2

## Difficulty of the task - Experiment 2

Our predictions about the difficulty of the task were:  

* WNOLFS <  WNOLA: The sequence rule can be used in both conditions but the exclusion rule can only be used in the WNOLFS condition, which might help. 
* MOONSQ < WNOLA: Only the sequence rule can be used in both conditions. Removing distracting visual cues makes finding the sequence rule easier

```{r Solution rates - Experiment 2}

F8 <- fisher.test(partic_groups2[c("wnolfs","wnola"), c("Nbof_solvers","Nbof_nonsolvers")])
F9 <- fisher.test(partic_groups2[c("moonsq","wnola"), c("Nbof_solvers","Nbof_nonsolvers")])

```

We analyzed the contingency table containing the number of solvers and non-solvers in pairs of conditions with Fisher's exact test. A p<0.05 means that the row/column association is statistically significant:

WNOLFS-WNOLA: **significant**  
`r pander(F8)`  

MOONSQ-WNOLA: **significant**  
`r pander(F9)`

## Aha feelings - Experiment 2

```{r Aha feelings - Experiment 2}

# Experiment 2 vs control:

F10 <- fisher.test(partic_groups2[c("wnolfs","wonly"), c("Nbof_ahas_solvers","Nbof_noahas_solvers")])
F11 <- fisher.test(partic_groups2[c("wnola","wonly"), c("Nbof_ahas_solvers","Nbof_noahas_solvers")])
F12 <- fisher.test(partic_groups2[c("moonsq","wonly"), c("Nbof_ahas_solvers","Nbof_noahas_solvers")])

```

We compared all conditions of Experiment 2 with the control condition (Letters Only).  

WNOLFS > WONLY: **significant**  
`r pander(F10)`   

WNOLA > WONLY: **significant**  
`r pander(F11)`  

MOONSQ > WONLY: **significant**
`r pander(F12)`   

# Other ideas

## Language

```{r Language}

#filter(participantdata_inc, participantdata_inc$numbers4letters == 1)

```

## Restructuring

Sliding average for move time

## Rules used (matching rule for moves)

## Correct rule

Does it correlate with problem difficulty or aha

## Aha-rate of non solvers

Correlates with difficulty?
Number of false ahas vs subjective difficulty or solution time

```{r Correlations}

plot(partic_groups$Failure_rate, partic_groups$Aha_rate_solvers, type="p")
plot(partic_groups$Median_task_time, partic_groups$Aha_rate_solvers, type="p")
plot(partic_groups$Median_task_time, partic_groups$Avg_nbof_moves, type="p")

```



## Goal of the experiment

## Participant plots

We can save plots for each participant, represeting their strategies.

```{r Plot}

if (1==0){
  participantdata_inc <- arrange(participantdata_inc, condition)
  for (i in participantdata_inc$index){
    P <- filter(participantdata,index==i)
    M <- filter(movedata, index==i)
    plot(M$timestamp, M$match)
    title(c(P$index, P$condition[], P$Solver))
  }
}

```




