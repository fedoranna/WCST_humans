---
title: "WCST analysis"
output:
  word_document: default
  html_document: default
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}

# PACKAGES
library(knitr)
library(dplyr)
library(stringdist)
library(reshape2)   
library(ggplot2)
library(openxlsx)

knitr::opts_chunk$set(echo = FALSE)

# Put all participant files in wd, and replace 4 files: survey.txt, vpn.txt, time.txt, prolific_export_5f917030b1ac5a05a2123cac.csv

# vpn.txt:
# 306: delete URL from ID
# 509: rewrite 4o to 40
# 894: random text copied into ID field
# survey: 886 wrote "d" for the level of difficulty field - delete it!

```

# Data

## Data sources

```{Parameters}

rm(list = ls()) # clear workspace
datadir = "C:/Users/fedor/OneDrive/Documents/R/WCST_humans/RESULTS/Round1/" # the directory where you put all the files from the server
url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vSkn-qNdPGKO3yf9LU3ed4WA_-XeM-3z7PecwM3-3A2tp1TeRJO8oZp4vAaoJjQY6FoclK77pi1Ixt7/pub?output=csv" # URL of the Google form with the missing survey answers

```

To run this script, copy-paste the following files to "datadir", and change "datadir" to your path to that folder: 

* prolific_export_5f917030b1ac5a05a2123cac.csv: this contains the demographic data of participants from Prolific
* all the result files from the server (one for each participant): these contain the data from the game (pattern: condition_ID_Results.txt) 
* vpn.txt from the server: this contains data from the pre-game questionnaire
* survey.txt from the server: this contains data from the post-game questionnaire
* time.txt from the server: this contains the timestamps of different action from the participants during the experiment (e.g., started game, filled out survey, etc.). This is not used for data analysis, but can be useful to check manually if something is not clear

We have manually made some modifications to these files to ensure that the data is read correctly.
In the vpn.txt file:  

* Participant 306: accidentally copied an URL next to their ID, we deleted the URL
* Participant 509: wrote "4o" for age, we corrected it to 40
* Participant 894: copy-pasted a random text to the ID field, we deleted it

In the survey.txt file:

* We deleted empty lines, where participants hit enter in a free text field for the following participants: 188,  237, 298, 363, 434, 529, 563, 582, 646, 763, 790
* Participant 593 wrote "10!" for difficulty, we corrected it to 10
* Participant 790, when describing the rule the html number &#62; appeared insead of ">"; we changed it back, so the rule reads "1>2>3>4."
* Participant 886 wrote "d" for the level of difficulty field - we deleted this entry
* We collected survey data separately for a few participants for whom the server froze during their survey. We made a google form with the survey questions and we asked participants to fill it out after they indicated their problem via the Prolific messaging system. This usually happened within a week of them completing the experiment. We excluded those answers where participants indicated that they do not remember the experiment well. Some participants proactively sent us their survey answers via messaging within the Prolific platform before we could send them the link for the google form. For these participants, we copy-pasted their answers from their message to the Google form.


```{r Read data, message=FALSE, warning=TRUE}

# Read data from common files
setwd(datadir)
vpndata <- read.table(paste(datadir, "vpn.txt", sep=""), 
                      header = FALSE, sep = ",",
                      col.names = c("index", "ID", "age", "sex", "vision", "colorblindness"),
                      colClasses = c("integer", "factor", "integer", "factor", "factor", "factor"))

surveydata <- read.table(paste(datadir, "survey.txt", sep=""),
                         header = FALSE, sep = "|", fill=TRUE,  quote = "",
                         col.names = c("condition", "index", "goal", "rule", "aha", "difficulty", "comments"),
                         colClasses = c("factor", "integer", "character", "character", "factor", "numeric", "character"))

timestampdata <- read.table(paste(datadir, "time.txt", sep=""), 
                            header = FALSE, sep = ",",
                            col.names = c("condition", "index", "event", "timestamp"),
                            colClasses = c("factor", "integer", "factor", "character"))

prolificfile <- list.files(datadir, pattern = "prolific_export_*" )
prolificdata <- read.csv(paste(datadir, prolificfile, sep=""), 
                         header = TRUE)

surveydata2 <- read.csv(url)

# Read data from resultfiles
resultfiles <- list.files(datadir, pattern = "*Results.txt" )
movedata <- c()
success <- data.frame(
  order = 1:length(resultfiles),
  index = NA,
  condition = NA,
  solver = NA,
  wentback = NA,
  resultfile = NA
)

for (i in 1:length(resultfiles))
{
  d <- read.table(paste(datadir, resultfiles[i], sep=""), 
                  header = FALSE, sep = ",",
                  colClasses = c("factor", "integer", "integer", "factor", "factor", "logical", "integer", "integer", "numeric"),
                  na.strings = "null") 
  
  # Solved the task?
  if (nrow(d)>17){
    s <- sum(d[(nrow(d)-17):nrow(d), 6]) == 18 
    } else {
      s <- FALSE}
  
  # Refreshed game or used back button?
  if (length(d[,3]) > length(unique(d[,3])))  {
    wentback <- TRUE
    } else {
      wentback <- FALSE}
  
  movedata <- rbind(movedata, d)

  success[i,"index"] <- d[1,2]
  success[i,"condition"] <- as.character(d[1,1])
  success[i,"solver"] <- s
  success[i,"wentback"] <- wentback
  success[i,"resultfile"] <- resultfiles[i]
  
}
colnames(movedata) <- c("condition", "index", "trial", "src_card", "tar_card", "match", "mv_time", "total_time", "timestamp")

```

We merged the data from these files into a data frame, called "participantdata".

```{r Modify and merge data frames, message=FALSE, warning=TRUE}

# The number of initiated sessions
sessions <- max(vpndata$index, na.rm=TRUE) + sum(is.na(vpndata$index))

# Merged participant data: success, vpndata, surveydata, prolificdata
participantdata <- data.frame(
  index = 1:sessions,
  prolific_action = NA)

conditions_ordered <- c("wlin", "wlout", "wnol", "wnolfs", "wnola", "moonsq", "wonly")

r1 = match(participantdata$index, success[,2])
participantdata$resultfile <- success[r1, 6]
participantdata$condition <- as.factor(success[r1, 3])
participantdata$solver <- success[r1, 4]
participantdata$wentback <- success[r1, 5]

r2 <- match(participantdata$index, vpndata$index)
participantdata$manual_ID <- vpndata$ID[r2]
participantdata$manual_age <- vpndata$age[r2]
participantdata$manual_sex <- vpndata$sex[r2]
participantdata$vision <- vpndata$vision[r2]
participantdata$colorblindness <- ifelse(vpndata$colorblindness[r2]=="not color blind", FALSE, TRUE)

r3 <- match(participantdata$index, surveydata$index)
participantdata$goal <- surveydata$goal[r3]
participantdata$rule <- surveydata$rule[r3]
participantdata$aha <- ifelse(surveydata$aha[r3]=="yes aha", TRUE, FALSE)
participantdata$difficulty <- surveydata$difficulty[r3]
participantdata$comments <- surveydata$comments[r3]

r4 <- match(participantdata$manual_ID, prolificdata$participant_id)
participantdata$session_id <- prolificdata$session_id[r4]
participantdata$prolific_ID <- prolificdata$participant_id[r4]
participantdata$status <- prolificdata$status[r4]
participantdata$started_datetime <- prolificdata$started_datetime[r4]
participantdata$completed_date_time <- prolificdata$completed_date_time[r4]
participantdata$time_taken <- prolificdata$time_taken[r4]
participantdata$prolific_age <- prolificdata$age[r4]
participantdata$num_approvals <- prolificdata$num_approvals[r4]
participantdata$num_rejections <- prolificdata$num_rejections[r4]
participantdata$prolific_score <- prolificdata$prolific_score[r4]
participantdata$reviewed_at_datetime <- prolificdata$reviewed_at_datetime[r4]
participantdata$entered_code <- prolificdata$entered_code[r4]
participantdata$country_of_birth <- prolificdata$Country.of.Birth[r4]
participantdata$current_country_of_residence <- prolificdata$Current.Country.of.Residence[r4]
participantdata$employment_status <- prolificdata$Employment.Status[r4]
participantdata$first_language_1 <- prolificdata$First.Language[r4]
participantdata$first_language_2 <- prolificdata$First.language[r4]
participantdata$nationality <- prolificdata$Nationality[r4]
participantdata$prolific_sex <- prolificdata$Sex[r4]
participantdata$student_status <- prolificdata$Student.Status[r4]

r5 <- match(participantdata$manual_ID, surveydata2$Your.Prolific.ID)
replace_these <- which(is.na(r5)==FALSE)
participantdata$goal[replace_these] <- as.character(surveydata2[r5[replace_these],3])
participantdata$rule[replace_these] <- as.character(surveydata2[r5[replace_these],4])
participantdata$aha[replace_these] <- ifelse(surveydata2[r5[replace_these],5]=="Yes", TRUE, FALSE)
participantdata$difficulty[replace_these] <- as.numeric(surveydata2[r5[replace_these],6])
participantdata$comments[replace_these] <- as.character(surveydata2[r5[replace_these],7])

# Reorder cinditions
participantdata$condition <- factor(participantdata$condition , levels=c("wlin", "wlout", "wnol", "wnolfs", "wnola", "moonsq", "wonly"))

# Modify
# check if difficulty is outside of range, e.g. 50 or 7.5


```

## Variables

```{r Calculate variables per move, warning = FALSE}

# Create think_time variable
movedata <- mutate(movedata, think_time = total_time - mv_time)

# Create matching_rule variable
movedata <- mutate(movedata,
                  matching_shape=NA,
                  matching_color=NA,
                  matching_number=NA)

for (r in 1:nrow(movedata)){
  movedata[r,"matching_shape"] = substr(movedata[r,4],1,1)==substr(movedata[r,5],1,1)
  movedata[r,"matching_color"] = substr(movedata[r,4],2,2)==substr(movedata[r,5],2,2)
  movedata[r,"matching_number"] = substr(movedata[r,4],3,3)==substr(movedata[r,5],3,3)
}

```

For each move participants made during the game we had the following variables:

* Trial number
* Source card
* Target card
* Match: correct or incorrect move
* Total time: the time elapsed between the source card appearing and the source card being dropped
* Move time: the time elapsed between dragging and dropping the source card
* Think time: total time - move time
* Rule: which rule the move conformed to (color, number, shape, index)

```{r Calculate variables per participant, warning = FALSE}

# Summarize movedata
sum_movedata <- movedata %>%
  group_by(index) %>%
  summarize(
    Nbof_moves = max(trial),
    Task_time = sum(total_time)/1000/60, #min
    Mean_total_time = mean(total_time), #ms
    Mean_move_time = mean(mv_time), #ms
    Mean_think_time = mean(think_time) # ms
  )

# Merge sum_movedata with participantdata
r6 <- match(participantdata$index, sum_movedata$index)
participantdata$nbof_moves <- sum_movedata$Nbof_moves[r6]
participantdata$task_time <- sum_movedata$Task_time[r6]
participantdata$mean_total_time <- sum_movedata$Mean_total_time[r6]
participantdata$mean_move_time <- sum_movedata$Mean_move_time[r6]
participantdata$mean_think_time <- sum_movedata$Mean_think_time[r6]

```

For each participant we calculated the following variables:

* Number of moves
* Task time: Time the participant spent with the task (min)
* Experiment time: The the participant spent with the entire experiment, including the surveys (min)
* Mean total time: mean time between moves (ms)
* Mean move time: mean time between drags and drops (ms)
* Mean think time: mean time the participant spent thinking between moves (total time - move time; ms)

## Exclusion criteria
```{r Exclude participants, message=FALSE, warning=FALSE}

# Exclude invalid cases
participantdata_f1 <- filter(participantdata, is.na(manual_ID)==FALSE)      # who did not fill out datasheet
participantdata_f2 <- filter(participantdata_f1, colorblindness==FALSE)     # who checked color-blindness
participantdata_f3 <- filter(participantdata_f2, is.na(resultfile)==FALSE)  # who did not start the game
participantdata_f4 <- filter(participantdata_f3, wentback==FALSE)           # who went back to the instructions page after making some moves in the game
participantdata_f5 <- filter(participantdata_f4, (country_of_birth == "CONSENT REVOKED")==FALSE) # who revoked consent
participantdata_f6 <- filter(participantdata_f5, duplicated(manual_ID)==FALSE)  # who played the game 2x (delete all attempts after the 1st)
participantdata_inc <- filter(participantdata_f6, is.na(aha)==FALSE) # who will be included in data analysis

# who did not get to survey (quit game early or did not press continue button after timeout) - count these as GAVE UP!!!
gave_up <- filter(participantdata_f6, is.na(aha))
# this criteria is not sufficient: these could be those for whom the server froze during the survey!!!

# who have missing game file, but survey is filled out - pay anyway, because this is server error

# Exclusion reasons for Prolific feedback
actions <- rep.int(NA, sessions)

temp <- is.element(participantdata$index, participantdata_inc$index)
actions[which(temp)] <- "PAY"

temp <- is.na(participantdata$aha)
actions[which(temp)] <- "quit"

temp <- duplicated(participantdata$manual_ID)
actions[which(temp)] <- "played_twice"

temp <- participantdata$country_of_birth == "CONSENT REVOKED"
actions[which(temp)] <- "revoked_consent"

temp <- participantdata$wentback
actions[which(temp)] <- "refreshed"

temp <- is.na(participantdata$resultfile)
actions[which(temp)] <- "quit"

temp <- participantdata$colorblindness
actions[which(temp)] <- "colorblind"

temp <- is.na(participantdata$manual_ID)
actions[which(temp)] <- "quit"

participantdata$prolific_action <- actions

# Excluded participants
participantdata_exc <- participantdata %>%
  filter(is.element(index, participantdata_inc$index) == FALSE) %>%
  arrange(prolific_ID)

participant_todo <- participantdata %>%
  filter(status == "AWAITING REVIEW") %>%
  select(prolific_ID, prolific_action) %>%
  arrange(prolific_ID)

temp <- filter(participant_todo, prolific_action == "PAY")
approved_list <- temp$prolific_ID # this can be copid to Prolific for batch approve

manually_reject <- filter(participant_todo, prolific_action != "PAY")

# exclude invalid cases and those who gave up from the other datasets too
# timestampdata_inc <- timestampdata %>%
#   filter(is.element(index, participantdata_inc$index)) %>%
#   arrange(index, timestamp)
# 
# prolificdata_inc <- prolificdata %>%
#   filter(is.element(participant_id, participantdata_inc$manual_ID)) %>%
#   arrange(participant_id)
# 
# movedata_inc <- movedata %>%
#   filter(is.element(index, participantdata_inc$index)) %>%
#   arrange(index)

```

We excluded participants who:

* Quit during the first data sheet: `r sessions - nrow(participantdata_f1)`
* Indicated that they were colorblind: `r nrow(participantdata_f1) - nrow(participantdata_f2)`
* Did not start the game after filling out the data sheet: `r nrow(participantdata_f2) - nrow(participantdata_f3)`
* Refreshed the screen during the game or went back to the instructions page after starting the game: `r nrow(participantdata_f3) - nrow(participantdata_f4)`
* Revoked their consent to use their data: `r nrow(participantdata_f4) - nrow(participantdata_f5)`
* Played the game more than once, even if they got assigned a different condition after the first time (we still included their first attempt though): `r nrow(participantdata_f5) - nrow(participantdata_f6)`
* Who did not fill out the final survey: `r nrow(participantdata_f6) - nrow(participantdata_inc)`

Those participants did not fill out the survey could be those, who 

* quit the experiment during the game before time out, or 
* left their computer and never pressed the "Continue" button after time out, or
* who finished their game, but who could not submit the survey, because the server froze. 

These participants did not complete the survey, but still have some data from the game.

For several participants, the screen froze on the survey page. For these participants we sent out the survey questions separately in a Google form. `r nrow(surveydata2)` participants completed the form, so we could include their data in the analyses.

Our participant funnel looked like this:

* The number of experimental sessions started: `r sessions`
* The number of participants who gave informed consent and filled out the first datasheet: `r nrow(participantdata_f1)`
* The number of participants who indicated that they were not colorblind: `r nrow(participantdata_f2)`
* The number of participants who started the game: `r nrow(participantdata_f3)`
* The number of participants who did not refresh the game or went back to the instructions page: `r nrow(participantdata_f4)`
* The number of participants who did not revoke their consent to use their data: `r nrow(participantdata_f5)`
* The number of participants who only played the game once: `r nrow(participantdata_f6)`
* The number of participants who did not give up during the game and filled out the last survey too: `r nrow(participantdata_inc)`

All-in-all, we excluded `r sessions - nrow(participantdata_inc)` initialized experimental sessions and we were left with `r nrow(participantdata_inc)` participants.

We need 78*7 = 546 participants. 
546 - `r nrow(participantdata_inc)` = `r 546 - nrow(participantdata_inc)` participants needed.

## To do on Prolific

Approve the participation and pay the following participants (to be copied to Prolific -> Approve by upload):
`r kable(approved_list, col.names="Batch approve list")`
  
  
Manually reject participation on Prolific:  

* If the same ID shows "quit" and then "played twice", approve anyway. These are probably cases where the game froze and then the participant restarted the experiment. 
* Check Messages too, because sometimes participants explain their technical difficulties there. 
* Check comments in the survey too, because sometimes it is obvious from their comments that they finished the experiment, even though they have missing data. 
  
`r kable(manually_reject)`

## Costs

We estimated that the median time for completing the experiment would be 8 minutes. The suggested hourly rate is 7.5 GBP on the Prolific website. From this, we calculated the fee for the task to be 1 GBP (independently of how long it took for the participant to finish). Together with 33% service fee and 20% VAT of the service fee, each approved participant costs around 1.396 GBP.

The time-out limit was calculated by the Prolific website to be 39 minutes for the whole experiment including the surveys (for the game, our own time-out was 15 minutes).

`r nrow(prolificdata)` participants initiated the experiment on the Prolific website. From this:  

* `r nrow(filter(prolificdata, status == "RETURNED"))` participants returned the task 
* `r nrow(filter(prolificdata, status == "TIMED-OUT"))` participants timed-out
* We excluded `r nrow(filter(prolificdata, status == "REJECTED"))` participants for various reasons (see above)
* We approved and paid the remaining `r nrow(filter(prolificdata, status == "APPROVED"))` participants
* From these, we could use the data of `r nrow(participantdata_inc)` participants

Sometimes we lost data because of server error. Other times, the browser of participants froze (probably also server error). In these cases, we cannot use the data of these participants, but we still have to pay them, because it was not their fault.

Costs for the experiment should be: `r nrow(filter(prolificdata, status == "APPROVED")) * 1.396`

The pilot experiments cost 73.23 GBP all together:

* Pilot 1: 33.60 GBP
* Pilot 2: 16.80 GBP
* Pilot 3: 14.01 GBP
* Pilot 4:  8.82 GBP


# Analyses

## Stopping criteria and further data cleaning:

We run the experiment until we had enough (78) participants in each condition after automatically evaluating them based on the exclusion criteria described above. First, the conditions were assigned randomly, then as we got closer to the desired number of participnats, we only let a certain number of participants to enter each condition to make up for the missing number of participants. This process was not exact, so we ended up with a few extra participants in some conditions. We stopped the experiment when each condition had at least 78 participants after the exclusions.    
We read the survey answers of the remaining participants and decided to exclude a few more:

* ...

After this manual excludion process,should we exclude the extra participants if there are more than 78 in a group?

```{r Manually exclude based on survey}

openxlsx::write.xlsx(participantdata_inc, file=paste(datadir, "included_participants.xlsx", sep=""), 
           sheetName = "Sheet1", col.names = TRUE, append = FALSE)

exclude_list <- c("x", "xx") # Prolific ID of excluded participants based on their survey answers

participantdata_inc2 <- filter(participantdata_inc, prolific_ID != exclude_list) # who will be included in data analysis



```

## Summary of conditions

```{r Summarize conditions}

partic_groups <- participantdata_inc2 %>%
  group_by(condition) %>%
  summarize(
    Nbof_participants = n_distinct(index),
    Nbof_solvers = sum(solver),
    Nbof_nonsolvers = Nbof_participants - Nbof_solvers,
    Failure_rate = Nbof_nonsolvers / Nbof_participants,
    Solution_rate = Nbof_solvers/Nbof_participants,
    Nbof_ahas = sum(aha),
    Aha_rate = Nbof_ahas/Nbof_participants,
    Nbof_ahas_solvers = sum(solver*aha),
    Aha_rate_solvers = Nbof_ahas_solvers / Nbof_solvers,
    Avg_task_time = mean(task_time),
    Avg_nbof_moves = mean(nbof_moves)
  )

partic_groups <- arrange(partic_groups, factor(condition, levels = c("wlin", "wlout", "wnol", "wnolfs", "wnola", "moonsq", "wonly")))
partic_groups_rownames <- tibble::column_to_rownames(partic_groups, "condition")

# WLIN <- filter(participantdata, condition=="wlin")
# WLOUT <- filter(participantdata, condition=="wlout")
# WNOL <- filter(participantdata, condition=="wnol")
# WNOLFS <- filter(participantdata, condition=="wnolfs")
# WNOLA <- filter(participantdata, condition=="wnola")
# MOONSQ <- filter(participantdata, condition=="moonsq")
# WONLY <- filter(participantdata, condition=="wonly")

kable(partic_groups[,c(1, 2, 10, 5, 11, 12)], 
      digits = 3,
      col.names = c("Condition", "Number of participants", "Aha rate of solvers", "Failure rate", "Avg task time", "Avg number of moves"))
# make this tables nicer: shorter headers, floating point numbers

missing <- (78 - partic_groups$Nbof_participants)

```

We need 78 participants per condition.  
**We need `r sum(missing[which(missing>0)])` more participants**  
**That is `r sum(missing[which(missing>0)]) * 1.396` GBP**

## Participant plots

```{r Plot}

if (1==0){
  participantdata_inc2 <- arrange(participantdata_inc2, condition)
  for (i in participantdata_inc2$index){
    P <- filter(participantdata,index==i)
    M <- filter(movedata, index==i)
    plot(M$timestamp, M$match)
    title(c(P$index, P$condition[], P$Solver))
  }
}

# Color points by rule!
# What if no rule is TRUE? What is more than 1 rule is TRUE?

```

## Difficulty of the task

### Solution rate: Fisher's exact tests

We analyzed the contingency table containing the number of solvers and non-solvers in pairs of conditions. A p<0.05 means that the row/column association is statistically significant. 

```{r Fisher tests}

barplot(partic_groups$Solution_rate, names.arg = partic_groups$condition, main="Solution rates")

# fisher.test(partic_groups2[c("wlin","wlout"), c("Nbof_solvers","Nbof_nonsolvers")])
# fisher.test(partic_groups2[c("wlout","wnol"), c("Nbof_solvers","Nbof_nonsolvers")])
# fisher.test(partic_groups2[c("wnolfs","wnola"), c("Nbof_solvers","Nbof_nonsolvers")])
# fisher.test(partic_groups2[c("moonsq","wnola"), c("Nbof_solvers","Nbof_nonsolvers")])




```

### Failure rate

```{r Fisher tests 2}

barplot(partic_groups$Failure_rate, names.arg = partic_groups$condition, main="Failure rates")

```

### Solution time: ANOVA

We checked whether the data was normally distributed with Kolmogorov-Smirnoff test:

```{r Normality}

#hist(participantdata_inc2$task_time)

# wlin_time <- participantdata_inc2 %>% filter(condition=="wlin") %>% select(task_time)
# wlin_time <- matrix(wlin_time[,1])
# 
# wlout_time <- participantdata_inc2 %>% filter(condition=="wlout") %>% select(task_time)
# wlout_time <- matrix(wlout_time[,1])
# 
# 
# 
# normality_wlin <- ks.test(
#   participantdata_inc2 %>% filter(condition=="wlin") %>% select(task_time), 
#   pnorm, alternative="two.sided", exact=NULL)
# normality_wlout <- ks.test(
#   participantdata_inc2 %>% filter(condition=="wlout") %>% select(task_time), 
#   pnorm, alternative="two.sided", exact=NULL)
# 
# normality_wlin
# normality_wlout

```
If the data is normally distributed, we use ANOVA, if it is not, we use Wilcoxon.

```{r ANOVA or Wilcoxon}

# greenhouse-geisser correction: robust also for non-normally distributed data

#participantdata_inc2$condition <- factor(participantdata_inc2$condition , levels=c("wlin", "wlout", "wnol", "wnolfs", "wnola", "moonsq", "wonly"))


boxplot(task_time ~ condition, 
        participantdata_inc2,
        ylab="Task time")

# if (normality_wlin$p.value > 0.05 && normality_wlout$p.value > 0.05) {
#   stati <- t.test(wlin_time, wlout_time,
#                   alternative="two.sided", paired=FALSE, var.equal=FALSE, conf.level=0.95)
#   } else {
#     stati <- wilcox.test(wlin_time, wlout_time,
#                          alternative="two.sided", paired=FALSE, exact=NULL, correct=TRUE, conf.int=TRUE, conf.level=0.95) # two sample Wilcoxon test is the same as the Mann-Whitney test
#   }
# 
# 
# stati

``` 

### Binary logistic regression



## Aha feelings: Fisher's exact test

```{r Aha-ratings}

barplot(partic_groups$Aha_rate_solvers, names.arg = partic_groups$condition, main="Aha rate of solvers")


```






