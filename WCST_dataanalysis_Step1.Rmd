---
title: "WCST data analysis - Step 1"
output:
  word_document: default
  html_document: default
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r Setup and parameters, include=FALSE}

# PACKAGES
library(knitr)
library(dplyr)
library(stringdist)
library(reshape2)   
library(ggplot2)
library(openxlsx)

knitr::opts_chunk$set(echo = FALSE)

rm(list = ls()) # clear workspace
datadir = "C:/Users/fedor/OneDrive/Documents/R/WCST_humans/RESULTS/Round1/" # the directory where you put all the files from the server
url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vSkn-qNdPGKO3yf9LU3ed4WA_-XeM-3z7PecwM3-3A2tp1TeRJO8oZp4vAaoJjQY6FoclK77pi1Ixt7/pub?output=csv" # URL of the Google form with the survey answers that were collected after the experiment

```

# Overview

We used this script for the following purposes:  

* to gather data from all the raw data files
* to merge data into a few data frames
* to calculate variables from the data
* to output data into excel spreadsheets for manual rating of the free text answers
* to exclude participants
* to save data frames

# Read data sources

To run this script, copy-paste the following files to "datadir", and change "datadir" to your path to that folder: 

* prolific_export_5f917030b1ac5a05a2123cac.csv: this contains the demographic data of participants from Prolific
* all the result files from the server (one for each participant): these contain the data from the game (file names: condition_ID_Results.txt) 
* vpn.txt from the server: this contains data from the pre-game questionnaire
* survey.txt from the server: this contains data from the post-game questionnaire
* time.txt from the server: this contains the timestamps of different actions from the participants during the experiment (e.g., started game, filled out survey, etc.). This is not used for data analysis, but can be useful to check manually if something is not clear

We have manually made some modifications to these files to ensure that the data is read correctly. In the vpn.txt file:  

* Participant 306: accidentally copied an URL next to their ID, we deleted the URL
* Participant 509: wrote "4o" for age, we corrected it to 40
* Participant 894: copy-pasted a random text to the ID field, we deleted it

In the survey.txt file:

* We deleted empty lines, where participants hit enter in a free text field for the following participants: 188,  237, 298, 363, 434, 529, 563, 582, 646, 763, 790
* Participant 593 wrote "10!" for difficulty, we corrected it to 10
* Participant 790, when describing the rule, the html number &#62; appeared insead of >; we changed it back, so the rule reads "1>2>3>4."
* Participant 886 wrote "d" for the level of difficulty field - we deleted this entry  

We collected survey data separately for a few participants for whom the server froze before they could submit their survey. We made a google form with the survey questions and we asked participants to fill it out after they indicated their problem via the Prolific messaging system. This usually happened within a week of them completing the experiment. One participant indicated that they do not remember the experiment well - we excluded their data. Some participants proactively sent us their survey answers via messaging within the Prolific platform before we could send them the link for the google form. For these participants, we copy-pasted their answers from their message to the Google form.

```{r Read data sources, message=FALSE, warning=TRUE}

# Read data from common files
setwd(datadir)
vpndata <- read.table(paste(datadir, "vpn.txt", sep=""), 
                      header = FALSE, sep = ",",
                      col.names = c("index", "ID", "age", "sex", "vision", "colorblindness"),
                      colClasses = c("integer", "factor", "integer", "factor", "factor", "factor"))

surveydata <- read.table(paste(datadir, "survey.txt", sep=""),
                         header = FALSE, sep = "|", fill=TRUE,  quote = "",
                         col.names = c("condition", "index", "goal", "rule", "aha", "difficulty", "comments"),
                         colClasses = c("factor", "integer", "character", "character", "factor", "numeric", "character"))

surveydata2 <- read.csv(url)

timestampdata <- read.table(paste(datadir, "time.txt", sep=""), 
                            header = FALSE, sep = ",",
                            col.names = c("condition", "index", "event", "timestamp"),
                            colClasses = c("factor", "integer", "factor", "character"))

prolificfile <- list.files(datadir, pattern = "prolific_export_*" )
prolificdata <- read.csv(paste(datadir, prolificfile, sep=""), 
                         header = TRUE)

# Read data from resultfiles and calculate some variables
resultfiles <- list.files(datadir, pattern = "*Results.txt" )
movedata <- c()
success <- data.frame(
  order = 1:length(resultfiles),
  index = NA,
  condition = NA,
  solver = NA,
  wentback = NA,
  resultfile = NA
)

for (i in 1:length(resultfiles))
{
  d <- read.table(paste(datadir, resultfiles[i], sep=""), 
                  header = FALSE, sep = ",",
                  colClasses = c("factor", "integer", "integer", "factor", "factor", "logical", "integer", "integer", "numeric"),
                  na.strings = "null") 
  
  # Solved the task?
  if (nrow(d)>17){
    s <- sum(d[(nrow(d)-17):nrow(d), 6]) == 18 
    } else {
      s <- FALSE}
  
  # Refreshed game or used back button?
  if (length(d[,3]) > length(unique(d[,3])))  {
    wentback <- TRUE
    } else {
      wentback <- FALSE}
  
  movedata <- rbind(movedata, d)

  success[i,"index"] <- d[1,2]
  success[i,"condition"] <- as.character(d[1,1])
  success[i,"solver"] <- s
  success[i,"wentback"] <- wentback
  success[i,"resultfile"] <- resultfiles[i]
  
}
colnames(movedata) <- c("condition", "index", "trial", "src_card", "tar_card", "match", "mv_time", "total_time", "timestamp")

```

# Merge data

We merged the data from the two survey files and the prolific file into a data frame, called "participantdata".

```{r Modify and merge data frames, message=FALSE, warning=TRUE}

# The number of initiated sessions
sessions <- max(vpndata$index, na.rm=TRUE) + sum(is.na(vpndata$index))

# Merged participant data: success, vpndata, surveydata, prolificdata
participantdata <- data.frame(
  index = 1:sessions,
  prolific_action = NA)

conditions_ordered <- c("wlin", "wlout", "wnol", "wnolfs", "wnola", "moonsq", "wonly")

r1 = match(participantdata$index, success[,2])
participantdata$resultfile <- success[r1, 6]
participantdata$condition <- as.factor(success[r1, 3])
participantdata$solver <- success[r1, 4]
participantdata$wentback <- success[r1, 5]

r2 <- match(participantdata$index, vpndata$index)
participantdata$manual_ID <- vpndata$ID[r2]
participantdata$manual_age <- vpndata$age[r2]
participantdata$manual_sex <- vpndata$sex[r2]
participantdata$vision <- vpndata$vision[r2]
participantdata$colorblindness <- ifelse(vpndata$colorblindness[r2]=="not color blind", FALSE, TRUE)

r3 <- match(participantdata$index, surveydata$index)
participantdata$goal <- surveydata$goal[r3]
participantdata$rule <- surveydata$rule[r3]
participantdata$aha <- ifelse(surveydata$aha[r3]=="yes aha", TRUE, FALSE)
participantdata$difficulty <- surveydata$difficulty[r3]
participantdata$comments <- surveydata$comments[r3]

r4 <- match(participantdata$manual_ID, prolificdata$participant_id)
participantdata$session_id <- prolificdata$session_id[r4]
participantdata$prolific_ID <- prolificdata$participant_id[r4]
participantdata$status <- prolificdata$status[r4]
participantdata$started_datetime <- prolificdata$started_datetime[r4]
participantdata$completed_date_time <- prolificdata$completed_date_time[r4]
participantdata$time_taken <- prolificdata$time_taken[r4]
participantdata$prolific_age <- prolificdata$age[r4]
participantdata$num_approvals <- prolificdata$num_approvals[r4]
participantdata$num_rejections <- prolificdata$num_rejections[r4]
participantdata$prolific_score <- prolificdata$prolific_score[r4]
participantdata$reviewed_at_datetime <- prolificdata$reviewed_at_datetime[r4]
participantdata$entered_code <- prolificdata$entered_code[r4]
participantdata$country_of_birth <- prolificdata$Country.of.Birth[r4]
participantdata$current_country_of_residence <- prolificdata$Current.Country.of.Residence[r4]
participantdata$employment_status <- prolificdata$Employment.Status[r4]
participantdata$first_language_1 <- prolificdata$First.Language[r4]
participantdata$first_language_2 <- prolificdata$First.language[r4]
participantdata$nationality <- prolificdata$Nationality[r4]
participantdata$prolific_sex <- prolificdata$Sex[r4]
participantdata$student_status <- prolificdata$Student.Status[r4]

r5 <- match(participantdata$manual_ID, surveydata2$Your.Prolific.ID)
replace_these <- which(is.na(r5)==FALSE)
participantdata$goal[replace_these] <- as.character(surveydata2[r5[replace_these],3])
participantdata$rule[replace_these] <- as.character(surveydata2[r5[replace_these],4])
participantdata$aha[replace_these] <- ifelse(surveydata2[r5[replace_these],5]=="Yes", TRUE, FALSE)
participantdata$difficulty[replace_these] <- as.numeric(surveydata2[r5[replace_these],6])
participantdata$comments[replace_these] <- as.character(surveydata2[r5[replace_these],7])

# Reorder conditions as factor (does not reorder rows in the data frame)
participantdata$condition <- factor(participantdata$condition , levels=conditions_ordered)

```

# Calculate variables

## Variables per move

For each move participants made during the game we had the following variables from the server:

* Trial number
* Source card
* Target card
* Match: correct or incorrect move
* Total time: the time elapsed between the source card appearing and the source card being dropped
* Move time: the time elapsed between dragging and dropping the source card
* Time stamp

Apart from these, we calculated a few more variables for each move:  

* Think time: total time - move time
* Matching shape: whether the move conformed to the shape rule
* Matching color: whether the move conformed to the color rule
* Matching number: whether the move conformed to the number rule

```{r Calculate variables per move, warning = FALSE}

# Create think_time variable
movedata <- mutate(movedata, think_time = total_time - mv_time)

# Create variables to see if participants used one of the standard rules
movedata <- mutate(movedata,
                  matching_shape=NA,
                  matching_color=NA,
                  matching_number=NA)

for (r in 1:nrow(movedata)){
  movedata[r,"matching_shape"] = substr(movedata[r,4],1,1)==substr(movedata[r,5],1,1)
  movedata[r,"matching_color"] = substr(movedata[r,4],2,2)==substr(movedata[r,5],2,2)
  movedata[r,"matching_number"] = substr(movedata[r,4],3,3)==substr(movedata[r,5],3,3)
}

```

## Variables per participant

We also calculated some descriptive variables for each participant based on their move data:

* Number of moves
* Task time (min): time spent with the task (only the card sorting game)
* Mean total time (ms): mean trial time 
* Mean move time (ms): mean drag and drop time
* Mean think time (ms): mean thinkning time

We merged these variables with the main data frame (participantdata).

```{r Calculate variables per participant, warning = FALSE}

# Summarize movedata
sum_movedata <- movedata %>%
  group_by(index) %>%
  summarize(
    Nbof_moves = max(trial),
    Task_time = sum(total_time)/1000/60, #mins spent with the game
    Mean_total_time = mean(total_time), #ms mean total trial time
    Mean_move_time = mean(mv_time), #ms mean move time
    Mean_think_time = mean(think_time) # ms mean think time
  )

# Merge sum_movedata with participantdata
r6 <- match(participantdata$index, sum_movedata$index)
participantdata$nbof_moves <- sum_movedata$Nbof_moves[r6]
participantdata$task_time <- sum_movedata$Task_time[r6]
participantdata$mean_total_time <- sum_movedata$Mean_total_time[r6]
participantdata$mean_move_time <- sum_movedata$Mean_move_time[r6]
participantdata$mean_think_time <- sum_movedata$Mean_think_time[r6]

```

# Exclusion criteria

```{r Exclude participants, message=FALSE, warning=FALSE}

# Exclude invalid cases
participantdata_f1 <- filter(participantdata, duplicated(manual_ID)==FALSE)  # who played the game 2x (delete all attempts after the 1st)
participantdata_f2 <- filter(participantdata_f1, is.na(manual_ID)==FALSE)      # who did not fill out the datasheet
participantdata_f3 <- filter(participantdata_f2, is.na(resultfile)==FALSE)  # who did not start the game
participantdata_f4 <- filter(participantdata_f3, wentback==FALSE)           # who went back to the instructions page after making some moves in the game
participantdata_f5 <- filter(participantdata_f4, is.na(aha)==FALSE)        # who did not fill out survey
participantdata_f6 <- filter(participantdata_f5, colorblindness==FALSE)     # who checked color-blindness
participantdata_f7 <- filter(participantdata_f6, task_time<15)              # who played longer than 15 min due to server error
participantdata_inc <- filter(participantdata_f7, (country_of_birth == "CONSENT REVOKED")==FALSE) # who revoked consent

# Who did not get to survey (quit game early or did not press continue button after timeout, or the server froze)
# consent revoked, timed out, returned could be also people who gave up - could correlate with the difficulty of the task

# Exclusion reasons for Prolific feedback
actions <- rep.int(NA, sessions)

temp <- is.element(participantdata$index, participantdata_inc$index)
actions[which(temp)] <- "PAY"

temp <- is.na(participantdata$aha)
actions[which(temp)] <- "quit"

temp <- duplicated(participantdata$manual_ID)
actions[which(temp)] <- "played_twice"

temp <- participantdata$country_of_birth == "CONSENT REVOKED"
actions[which(temp)] <- "revoked_consent"

temp <- participantdata$wentback
actions[which(temp)] <- "refreshed"

temp <- is.na(participantdata$resultfile)
actions[which(temp)] <- "quit"

temp <- participantdata$colorblindness
actions[which(temp)] <- "colorblind"

temp <- is.na(participantdata$manual_ID)
actions[which(temp)] <- "quit"

participantdata$prolific_action <- actions

# Excluded participants
participantdata_exc <- participantdata %>%
  filter(is.element(index, participantdata_inc$index) == FALSE) %>%
  arrange(prolific_ID)

participant_todo <- participantdata %>%
  filter(status == "AWAITING REVIEW") %>%
  select(prolific_ID, prolific_action) %>%
  arrange(prolific_ID)

temp <- filter(participant_todo, prolific_action == "PAY")
approved_list <- temp$prolific_ID # this can be copid to Prolific for batch approve

manually_reject <- filter(participant_todo, prolific_action != "PAY")

# exclude invalid cases and those who gave up from the other datasets too
timestampdata_inc <- timestampdata %>%
  filter(is.element(index, participantdata_inc$index)) %>%
  arrange(index, timestamp)

prolificdata_inc <- prolificdata %>%
  filter(is.element(participant_id, participantdata_inc$manual_ID)) %>%
  arrange(participant_id)

movedata_inc <- movedata %>%
  filter(is.element(index, participantdata_inc$index)) %>%
  arrange(index)

```

We excluded entries where the participant:

* Played the game more than once, even if they got assigned a different condition after the first time (we still included their first attempt though): `r nrow(participantdata_f1) - nrow(participantdata)`
* Did not fill out the first data sheet: `r nrow(participantdata_f2) - nrow(participantdata_f1)`
* Did not start the game after filling out the data sheet: `r nrow(participantdata_f3) - nrow(participantdata_f2)`
* Refreshed the screen during the game or went back to the instructions page after starting the game: `r nrow(participantdata_f4) - nrow(participantdata_f3)`
* Who did not fill out the final survey: `r nrow(participantdata_f5) - nrow(participantdata_f4)`
* Indicated that they were colorblind: `r nrow(participantdata_f6) - nrow(participantdata_f5)`
* Revoked their consent to use their data: `r nrow(participantdata_inc) - nrow(participantdata_f6)`

Those participants who did not fill out the survey could be those, who 

* quit the experiment during the game before time out, or 
* left their computer and never pressed the "Continue" button after time out, or
* who finished their game, but who could not submit the survey, because the server froze. 

Our participant funnel looked like this:

* The number of experimental sessions started: `r sessions`
* The number of participants who properly finished the experiment and surveys without refreshing the screen or going back in their browser: `r nrow(participantdata_f5)`
* From these, the number of participants who were not colorblind: `r nrow(participantdata_f6)`
* From these, the number of participants who did not revoke their consent to use their data: `r nrow(participantdata_inc)`

All-in-all, we excluded `r sessions - nrow(participantdata_inc)` initialized experimental sessions and we were left with `r nrow(participantdata_inc)` participants.

# Stopping criteria

## Stopping rule
We run the experiment until we had enough *(78) participants in each condition* after automatically evaluating them based on the exclusion criteria described above. First, the conditions were assigned randomly, then as we got closer to the desired number of participnats, we only let a certain number of participants to enter each condition to make up for the missing number of participants. This process was not exact, so we ended up with a few extra participants in some conditions. We stopped the experiment when each condition had at least 78 participants after the exclusions.    

```{r Summarize conditions}

partic_groups <- participantdata_inc %>%
  group_by(condition) %>%
  summarize(
    Nbof_participants = n_distinct(index),
    Nbof_solvers = sum(solver),
    Nbof_nonsolvers = Nbof_participants - Nbof_solvers,
    Failure_rate = Nbof_nonsolvers / Nbof_participants,
    Solution_rate = Nbof_solvers/Nbof_participants,
    Nbof_ahas = sum(aha),
    Aha_rate = Nbof_ahas/Nbof_participants,
    Nbof_ahas_solvers = sum(solver*aha),
    Aha_rate_solvers = Nbof_ahas_solvers / Nbof_solvers,
    Avg_task_time = mean(task_time),
    Avg_nbof_moves = mean(nbof_moves)
  )

partic_groups <- arrange(partic_groups, factor(condition, levels = c("wlin", "wlout", "wnol", "wnolfs", "wnola", "moonsq", "wonly")))
partic_groups_rownames <- tibble::column_to_rownames(partic_groups, "condition")

kable(partic_groups[,c(1, 2, 10, 5, 11, 12)], 
      digits = 3,
      col.names = c("Condition", "Number of participants", "Aha rate of solvers", "Failure rate", "Avg task time", "Avg number of moves"))

```

## To do on Prolific

Approve the participation and pay the following participants (to be copied to Prolific -> Approve by upload):
`r kable(approved_list, col.names="Batch approve list")`
  
Manually reject participation on Prolific:  

* If the same ID shows "quit" and then "played twice", approve anyway. These are probably cases where the game froze and then the participant restarted the experiment. 
* Check Messages too, because sometimes participants explain their technical difficulties there. 
* Check comments in the survey too, because sometimes it is obvious from their comments that they finished the experiment, even though they have missing data. 
  
`r kable(manually_reject)`

## Costs

We estimated that the median time for completing the experiment would be 8 minutes. The suggested hourly rate is 7.5 GBP on the Prolific website. From this, we calculated the fee for the task to be 1 GBP (independently of how long it took for the participant to finish). Together with 33% service fee and 20% VAT of the service fee, each approved participant costs around 1.396 GBP.

The time-out limit was calculated by the Prolific website to be 39 minutes for the whole experiment including the surveys (for the game, our own time-out was 15 minutes).

`r nrow(prolificdata)` participants initiated the experiment on the Prolific website. From this:  

* `r nrow(filter(prolificdata, status == "RETURNED"))` participants returned the task 
* `r nrow(filter(prolificdata, status == "TIMED-OUT"))` participants timed-out
* We excluded `r nrow(filter(prolificdata, status == "REJECTED"))` participants for various reasons (see above)
* We approved and paid the remaining `r nrow(filter(prolificdata, status == "APPROVED"))` participants
* From these, we could use the data of `r nrow(participantdata_inc)` participants

Sometimes we lost data because of server error. Other times, the screen of participants froze (probably also server error). In these cases, we cannot use the data of these participants, but we still have to pay them, because it was not their fault.

Costs for the experiment should be: `r nrow(filter(prolificdata, status == "APPROVED")) * 1.396`

The pilot experiments cost 73.23 GBP all together:

* Pilot 1: 33.60 GBP
* Pilot 2: 16.80 GBP
* Pilot 3: 14.01 GBP
* Pilot 4:  8.82 GBP

# Save data

## Data files

* We saved all dataframes that should be used in Step 2 as "_Step1_output.RData".  
* We saved free text answers for manual rating as "_free_text_answers.xlsx"

```{r Saving and printing}

# Print participantdata for human reading
openxlsx::write.xlsx(participantdata_inc, file=paste(datadir, "_included_participants.xlsx", sep=""), 
           sheetName = "Sheet1", col.names = TRUE, append = FALSE)

# Print free text answers for human rating
free_text_answers <- participantdata_inc %>%
  arrange(condition) %>%
  select(index, condition, solver, aha, difficulty, goal, comments, rule)

openxlsx::write.xlsx(free_text_answers, file=paste(datadir, "_free_text_answers.xlsx", sep=""), 
           sheetName = "Sheet1", col.names = TRUE, append = FALSE)

# Save dataframes 
save(
  movedata, participantdata_inc,
  file = "_Step1_output.RData"
)
save.image()

```

## Participant plots

We can save plots for each participant, represeting their strategies.

```{r Plot}

if (1==0){
  participantdata_inc <- arrange(participantdata_inc, condition)
  for (i in participantdata_inc$index){
    P <- filter(participantdata,index==i)
    M <- filter(movedata, index==i)
    plot(M$timestamp, M$match)
    title(c(P$index, P$condition[], P$Solver))
  }
}

```





