} else {
PCHRF[1, "feeding"] <- "A"
}
} else {
PCHRF[1, "feeding"] <- "A"
if (yourdata$Do_you_stay_in_the_room_until_your_baby_falls_asleep_and_maybe_even_longer=="Yes"){
PCHRF[1, "presence"] <- "C"
if (yourdata$Do_you_sometimes_stroke_or_pat_your_baby_or_put_your_hand_on_his_back_if_he_fusses_or_cries_without_picking_him_up=="Yes"){
PCHRF[1, "contact"] <- "I"
} else {
PCHRF[1, "contact"] <- "A"
}
if (yourdata$Do_you_sometimes_pick_you_baby_up_if_he_fusses_or_cries=="Yes"){
PCHRF[1, "holding"] <- "I"
if (yourdata$Do_you_sometimes_stroke_or_pat_your_baby_or_put_your_hand_on_his_back_if_he_fusses_or_cries_without_picking_him_up=="Yes"){
PCHRF[1, "contact"] <- "I"
} else {
PCHRF[1, "contact"] <- "A"
}
if (yourdata$Do_you_sometimes_pick_you_baby_up_if_he_fusses_or_cries=="Yes"){
PCHRF[1, "holding"] <- "I"
} else {
PCHRF[1, "holding"] <- "A"
}
} else {
PCHRF[1, "holding"] <- "A"
}
} else {
if (yourdata$Do_you_go_back_to_the_room_a_few_times_if_your_baby_fusses_or_cries=="Yes"){
PCHRF[1, "presence"] <- "I"
} else {
PCHRF[1, "presence"] <- "A"
}
}
}
}
if (yourdata$Do_you_transfer_your_baby_to_somewhere_else_after_he_falls_asleep=="No, the baby stays where he falls asleep."){
transfer <- "FALSE"
} else {transfer <- "TRUE"}
for (i in 1:nrow(codetable)){
if (sum(codetable[i,1:5]==PCHRF)==5){
index<-i
}
}
names(yourdata)
2.6/3.3
1.3/3.3
1.4*3.3
0.4*3.3
0.1*3.3
library(knitr)
library(kableExtra)
dt <- mtcars[1:5, 1:6]
"simple"
dt
"format=html"
kable(dt, format="html")
"format=latex"
kable(dt, format="latex")
"format=default"
kable(dt)
names(dt)
names(dt)[1]
install.packages("readstata13")
library(readstata13)
rm(list=ls())
knitr::opts_chunk$set(echo = FALSE, error=FALSE, message=FALSE, warning=FALSE, include=FALSE)
library(knitr)
library(janitor)
library(eeptools)
library(R.utils)
R.utils::sourceDirectory("C:/Users/fedor/OneDrive/Documents/R/myfunctions/", modifiedOnly=FALSE)
# Parameters
row <- 12
url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vRBt_HvbEuLl2-z3ONwVr_ouDdT2POfXC8rR7KeiOQR03SmHevGr5NCBMcFQdD4YRgMm5iW0TGqTOK3/pub?gid=1216819939&single=true&output=csv"
rec_short <- matrix(nrow=7, ncol=5, byrow=TRUE,
dimnames = list(
c("Newborn", "Infant", "Toddler", "Preschooler", "School-age", "Adolescent", "Adult"),
c("Months", "Maybe_min", "Rec_min", "Rec_max", "Maybe_max")),
data = c(
0, 11, 14, 17, 19,
4, 10, 12, 15, 18,
12, 9, 11, 14, 16,
3*12, 8, 10, 13, 14,
6*12, 7, 9, 11, 12,
14*12, 7, 8, 10, 11,
18*12, 6, 7, 9, 11))
rec_grad <- TableExpander_gradual(rec_short)
alldata <- read.csv(url)
alldata <- clean_names(alldata, case="parsed")
timestamp <- strptime(alldata[row-1,1], format="%m/%d/%Y %H:%M:%S")
birthday <- strptime(alldata[row-1,2], format="%m/%d/%Y")
preterm <- alldata[row-1,3]
nightsleep <- alldata[row-1,4]
daysleep <- alldata[row-1,5]
naps <- alldata[row-1,6]
mood <- alldata[row-1,7]
baby <- alldata[row-1,8]
gender <- alldata[row-1,9]
parent <- alldata[row-1,10]
email <- alldata[row-1,11]
newsletter <- alldata[row-1,13]
View(alldata)
rm(list=ls())
knitr::opts_chunk$set(echo = FALSE, error=FALSE, message=FALSE, warning=FALSE, include=FALSE)
library(knitr)
rm(list=ls())
knitr::opts_chunk$set(echo = FALSE, error=FALSE, message=FALSE, warning=FALSE, include=FALSE)
library(knitr)
library(janitor)
library(eeptools)
library(R.utils)
R.utils::sourceDirectory("C:/Users/fedor/OneDrive/Documents/R/myfunctions/", modifiedOnly=FALSE)
# library(googleformr) # does not work
# library(googlesheets) # does not wor
# require(RCurl) # works on published sheets, but unnecessary
# Parameters
row <- 12
url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vR1-6KhuUKR-LA6P35OEEU14kDuMx9OyuLl1f0EByQVBKyxhapGKDFtYd2tCp3DFIT6RtZhH2fhNGLy/pub?gid=875867982&single=true&output=csv"
# Google Spreadsheet with the responses: File -> Publish to the web -> as csv
# https://www.sleepfoundation.org/excessive-sleepiness/support/how-much-sleep-do-babies-and-kids-need
rec_short <- matrix(nrow=7, ncol=5, byrow=TRUE,
dimnames = list(
c("Newborn", "Infant", "Toddler", "Preschooler", "School-age", "Adolescent", "Adult"),
c("Months", "Maybe_min", "Rec_min", "Rec_max", "Maybe_max")),
data = c(
0, 11, 14, 17, 19,
4, 10, 12, 15, 18,
12, 9, 11, 14, 16,
3*12, 8, 10, 13, 14,
6*12, 7, 9, 11, 12,
14*12, 7, 8, 10, 11,
18*12, 6, 7, 9, 11))
rec_grad <- TableExpander_gradual(rec_short)
alldata <- read.csv(url)
alldata <- clean_names(alldata, case="parsed")
timestamp <- strptime(alldata[row-1,1], format="%m/%d/%Y %H:%M:%S")
birthday <- strptime(alldata[row-1,2], format="%m/%d/%Y")
preterm <- alldata[row-1,3]
nightsleep <- alldata[row-1,4]
daysleep <- alldata[row-1,5]
naps <- alldata[row-1,6]
mood <- alldata[row-1,7]
baby <- alldata[row-1,8]
gender <- alldata[row-1,9]
parent <- alldata[row-1,10]
email <- alldata[row-1,11]
newsletter <- alldata[row-1,13]
age <- age_calc(as.Date(birthday), enddate = as.Date(timestamp), units = "months", precise = TRUE)
if (is.na(preterm)){preterm<-0}
age <- age - preterm/4
if (age<-0){age<-0}
age <- floor(age)
allsleep <- nightsleep + daysleep
if (mood == "He/she is generally alert and in a good mood during the day."){mood_code<-3}
if (mood == "It varies."){mood_code<-2}
if (mood == "He/she is fussy and looks tired most of the time."){mood_code<-1}
pronouns <- Pronouns(gender)
newsletter <- ifelse(newsletter == "I would like to subscribe to the Dreamsense newsletter (I can always unsubscribe).", 1, 0)
email
alldata <- read.csv(url)
alldata <- clean_names(alldata, case="parsed")
timestamp <- strptime(alldata[row-1,1], format="%m/%d/%Y %H:%M:%S")
email <- alldata[row-1,2]
birthday <- strptime(alldata[row-1,3], format="%m/%d/%Y")
preterm <- alldata[row-1,4]
nightsleep <- alldata[row-1,5]
daysleep <- alldata[row-1,6]
naps <- alldata[row-1,7]
mood <- alldata[row-1,8]
baby <- alldata[row-1,9]
gender <- alldata[row-1,10]
parent <- alldata[row-1,11]
newsletter <- alldata[row-1,12]
age <- age_calc(as.Date(birthday), enddate = as.Date(timestamp), units = "months", precise = TRUE)
if (is.na(preterm)){preterm<-0}
age <- age - preterm/4
if (age<-0){age<-0}
age <- floor(age)
allsleep <- nightsleep + daysleep
if (mood == "He/she is generally alert and in a good mood during the day."){mood_code<-3}
if (mood == "It varies."){mood_code<-2}
if (mood == "He/she is fussy and looks tired most of the time."){mood_code<-1}
pronouns <- Pronouns(gender)
newsletter <- ifelse(newsletter == "I would like to subscribe to the Dreamsense newsletter (I can always unsubscribe).", 1, 0)
nirthday
birthday
timestamp
age
preterm
as.Date(birthday)
as.Date(timestamp)
age_calc(as.Date(birthday), enddate = as.Date(timestamp), units = "months", precise = TRUE)
is.na(preterm)
preterm/4
age <- age_calc(as.Date(birthday), enddate = as.Date(timestamp), units = "months", precise = TRUE)
age
if (is.na(preterm)){preterm<-0}
age <- age - preterm/4
if (age<0){age<-0}
age <- floor(age)
age
newsletter
print(email)
print(newsletter)
# Chunk 1: setup
# PACKAGES
library(knitr)
library(dplyr)
library(stringdist)
library(reshape2)
library(ggplot2)
library(openxlsx)
knitr::opts_chunk$set(echo = FALSE)
# Put all participant files in wd, and replace 4 files:
# - survey.txt,
# - vpn.txt,
# - time.txt,
# - prolific_export_5f917030b1ac5a05a2123cac.csv
# Chunk 2: Parameters
rm(list = ls()) # clear workspace
datadir = "C:/Users/fedor/OneDrive/Documents/R/WCST_humans/RESULTS/Round1/" # the directory where you put all the files from the server
url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vSkn-qNdPGKO3yf9LU3ed4WA_-XeM-3z7PecwM3-3A2tp1TeRJO8oZp4vAaoJjQY6FoclK77pi1Ixt7/pub?output=csv" # URL of the Google form with the missing survey answers
# Chunk 3: Read data
# Read data from common files
setwd(datadir)
vpndata <- read.table(paste(datadir, "vpn.txt", sep=""),
header = FALSE, sep = ",",
col.names = c("index", "ID", "age", "sex", "vision", "colorblindness"),
colClasses = c("integer", "factor", "integer", "factor", "factor", "factor"))
surveydata <- read.table(paste(datadir, "survey.txt", sep=""),
header = FALSE, sep = "|", fill=TRUE,  quote = "",
col.names = c("condition", "index", "goal", "rule", "aha", "difficulty", "comments"),
colClasses = c("factor", "integer", "character", "character", "factor", "numeric", "character"))
timestampdata <- read.table(paste(datadir, "time.txt", sep=""),
header = FALSE, sep = ",",
col.names = c("condition", "index", "event", "timestamp"),
colClasses = c("factor", "integer", "factor", "character"))
prolificfile <- list.files(datadir, pattern = "prolific_export_*" )
prolificdata <- read.csv(paste(datadir, prolificfile, sep=""),
header = TRUE)
surveydata2 <- read.csv(url)
# Read data from resultfiles
resultfiles <- list.files(datadir, pattern = "*Results.txt" )
movedata <- c()
success <- data.frame(
order = 1:length(resultfiles),
index = NA,
condition = NA,
solver = NA,
wentback = NA,
resultfile = NA
)
for (i in 1:length(resultfiles))
{
d <- read.table(paste(datadir, resultfiles[i], sep=""),
header = FALSE, sep = ",",
colClasses = c("factor", "integer", "integer", "factor", "factor", "logical", "integer", "integer", "numeric"),
na.strings = "null")
# Solved the task?
if (nrow(d)>17){
s <- sum(d[(nrow(d)-17):nrow(d), 6]) == 18
} else {
s <- FALSE}
# Refreshed game or used back button?
if (length(d[,3]) > length(unique(d[,3])))  {
wentback <- TRUE
} else {
wentback <- FALSE}
movedata <- rbind(movedata, d)
success[i,"index"] <- d[1,2]
success[i,"condition"] <- as.character(d[1,1])
success[i,"solver"] <- s
success[i,"wentback"] <- wentback
success[i,"resultfile"] <- resultfiles[i]
}
colnames(movedata) <- c("condition", "index", "trial", "src_card", "tar_card", "match", "mv_time", "total_time", "timestamp")
# Chunk 4: Modify and merge data frames
# The number of initiated sessions
sessions <- max(vpndata$index, na.rm=TRUE) + sum(is.na(vpndata$index))
# Merged participant data: success, vpndata, surveydata, prolificdata
participantdata <- data.frame(
index = 1:sessions,
prolific_action = NA)
conditions_ordered <- c("wlin", "wlout", "wnol", "wnolfs", "wnola", "moonsq", "wonly")
r1 = match(participantdata$index, success[,2])
participantdata$resultfile <- success[r1, 6]
participantdata$condition <- as.factor(success[r1, 3])
participantdata$solver <- success[r1, 4]
participantdata$wentback <- success[r1, 5]
r2 <- match(participantdata$index, vpndata$index)
participantdata$manual_ID <- vpndata$ID[r2]
participantdata$manual_age <- vpndata$age[r2]
participantdata$manual_sex <- vpndata$sex[r2]
participantdata$vision <- vpndata$vision[r2]
participantdata$colorblindness <- ifelse(vpndata$colorblindness[r2]=="not color blind", FALSE, TRUE)
r3 <- match(participantdata$index, surveydata$index)
participantdata$goal <- surveydata$goal[r3]
participantdata$rule <- surveydata$rule[r3]
participantdata$aha <- ifelse(surveydata$aha[r3]=="yes aha", TRUE, FALSE)
participantdata$difficulty <- surveydata$difficulty[r3]
participantdata$comments <- surveydata$comments[r3]
r4 <- match(participantdata$manual_ID, prolificdata$participant_id)
participantdata$session_id <- prolificdata$session_id[r4]
participantdata$prolific_ID <- prolificdata$participant_id[r4]
participantdata$status <- prolificdata$status[r4]
participantdata$started_datetime <- prolificdata$started_datetime[r4]
participantdata$completed_date_time <- prolificdata$completed_date_time[r4]
participantdata$time_taken <- prolificdata$time_taken[r4]
participantdata$prolific_age <- prolificdata$age[r4]
participantdata$num_approvals <- prolificdata$num_approvals[r4]
participantdata$num_rejections <- prolificdata$num_rejections[r4]
participantdata$prolific_score <- prolificdata$prolific_score[r4]
participantdata$reviewed_at_datetime <- prolificdata$reviewed_at_datetime[r4]
participantdata$entered_code <- prolificdata$entered_code[r4]
participantdata$country_of_birth <- prolificdata$Country.of.Birth[r4]
participantdata$current_country_of_residence <- prolificdata$Current.Country.of.Residence[r4]
participantdata$employment_status <- prolificdata$Employment.Status[r4]
participantdata$first_language_1 <- prolificdata$First.Language[r4]
participantdata$first_language_2 <- prolificdata$First.language[r4]
participantdata$nationality <- prolificdata$Nationality[r4]
participantdata$prolific_sex <- prolificdata$Sex[r4]
participantdata$student_status <- prolificdata$Student.Status[r4]
r5 <- match(participantdata$manual_ID, surveydata2$Your.Prolific.ID)
replace_these <- which(is.na(r5)==FALSE)
participantdata$goal[replace_these] <- as.character(surveydata2[r5[replace_these],3])
participantdata$rule[replace_these] <- as.character(surveydata2[r5[replace_these],4])
participantdata$aha[replace_these] <- ifelse(surveydata2[r5[replace_these],5]=="Yes", TRUE, FALSE)
participantdata$difficulty[replace_these] <- as.numeric(surveydata2[r5[replace_these],6])
participantdata$comments[replace_these] <- as.character(surveydata2[r5[replace_these],7])
# Reorder cinditions
participantdata$condition <- factor(participantdata$condition , levels=c("wlin", "wlout", "wnol", "wnolfs", "wnola", "moonsq", "wonly"))
# Modify
# check if difficulty is outside of range, e.g. 50 or 7.5
# Chunk 5: Calculate variables per move
# Create think_time variable
movedata <- mutate(movedata, think_time = total_time - mv_time)
# Create matching_rule variable
movedata <- mutate(movedata,
matching_shape=NA,
matching_color=NA,
matching_number=NA)
for (r in 1:nrow(movedata)){
movedata[r,"matching_shape"] = substr(movedata[r,4],1,1)==substr(movedata[r,5],1,1)
movedata[r,"matching_color"] = substr(movedata[r,4],2,2)==substr(movedata[r,5],2,2)
movedata[r,"matching_number"] = substr(movedata[r,4],3,3)==substr(movedata[r,5],3,3)
}
# Chunk 6: Calculate variables per participant
# Summarize movedata
sum_movedata <- movedata %>%
group_by(index) %>%
summarize(
Nbof_moves = max(trial),
Task_time = sum(total_time)/1000/60, #min
Mean_total_time = mean(total_time), #ms
Mean_move_time = mean(mv_time), #ms
Mean_think_time = mean(think_time) # ms
)
# Merge sum_movedata with participantdata
r6 <- match(participantdata$index, sum_movedata$index)
participantdata$nbof_moves <- sum_movedata$Nbof_moves[r6]
participantdata$task_time <- sum_movedata$Task_time[r6]
participantdata$mean_total_time <- sum_movedata$Mean_total_time[r6]
participantdata$mean_move_time <- sum_movedata$Mean_move_time[r6]
participantdata$mean_think_time <- sum_movedata$Mean_think_time[r6]
# Chunk 7: Exclude participants
# Exclude invalid cases
participantdata_f1 <- filter(participantdata, is.na(manual_ID)==FALSE)      # who did not fill out datasheet
participantdata_f2 <- filter(participantdata_f1, colorblindness==FALSE)     # who checked color-blindness
participantdata_f3 <- filter(participantdata_f2, is.na(resultfile)==FALSE)  # who did not start the game
participantdata_f4 <- filter(participantdata_f3, wentback==FALSE)           # who went back to the instructions page after making some moves in the game
participantdata_f5 <- filter(participantdata_f4, (country_of_birth == "CONSENT REVOKED")==FALSE) # who revoked consent
participantdata_f6 <- filter(participantdata_f5, duplicated(manual_ID)==FALSE)  # who played the game 2x (delete all attempts after the 1st)
participantdata_inc <- filter(participantdata_f6, is.na(aha)==FALSE) # who will be included in data analysis
# who did not get to survey (quit game early or did not press continue button after timeout) - count these as GAVE UP!!!
gave_up <- filter(participantdata_f6, is.na(aha))
# this criteria is not sufficient: these could be those for whom the server froze during the survey!!!
# who have missing game file, but survey is filled out - pay anyway, because this is server error
# Exclusion reasons for Prolific feedback
actions <- rep.int(NA, sessions)
temp <- is.element(participantdata$index, participantdata_inc$index)
actions[which(temp)] <- "PAY"
temp <- is.na(participantdata$aha)
actions[which(temp)] <- "quit"
temp <- duplicated(participantdata$manual_ID)
actions[which(temp)] <- "played_twice"
temp <- participantdata$country_of_birth == "CONSENT REVOKED"
actions[which(temp)] <- "revoked_consent"
temp <- participantdata$wentback
actions[which(temp)] <- "refreshed"
temp <- is.na(participantdata$resultfile)
actions[which(temp)] <- "quit"
temp <- participantdata$colorblindness
actions[which(temp)] <- "colorblind"
temp <- is.na(participantdata$manual_ID)
actions[which(temp)] <- "quit"
participantdata$prolific_action <- actions
# Excluded participants
participantdata_exc <- participantdata %>%
filter(is.element(index, participantdata_inc$index) == FALSE) %>%
arrange(prolific_ID)
participant_todo <- participantdata %>%
filter(status == "AWAITING REVIEW") %>%
select(prolific_ID, prolific_action) %>%
arrange(prolific_ID)
temp <- filter(participant_todo, prolific_action == "PAY")
approved_list <- temp$prolific_ID # this can be copid to Prolific for batch approve
manually_reject <- filter(participant_todo, prolific_action != "PAY")
# exclude invalid cases and those who gave up from the other datasets too
# timestampdata_inc <- timestampdata %>%
#   filter(is.element(index, participantdata_inc$index)) %>%
#   arrange(index, timestamp)
#
# prolificdata_inc <- prolificdata %>%
#   filter(is.element(participant_id, participantdata_inc$manual_ID)) %>%
#   arrange(participant_id)
#
# movedata_inc <- movedata %>%
#   filter(is.element(index, participantdata_inc$index)) %>%
#   arrange(index)
# Chunk 8: Manually exclude based on survey
openxlsx::write.xlsx(participantdata_inc, file=paste(datadir, "included_participants.xlsx", sep=""),
sheetName = "Sheet1", col.names = TRUE, append = FALSE)
exclude_list <- c("x", "xx") # Prolific ID of excluded participants based on their survey answers
participantdata_inc2 <- filter(participantdata_inc, prolific_ID != exclude_list) # who will be included in data analysis
# Chunk 9: Summarize conditions
partic_groups <- participantdata_inc2 %>%
group_by(condition) %>%
summarize(
Nbof_participants = n_distinct(index),
Nbof_solvers = sum(solver),
Nbof_nonsolvers = Nbof_participants - Nbof_solvers,
Failure_rate = Nbof_nonsolvers / Nbof_participants,
Solution_rate = Nbof_solvers/Nbof_participants,
Nbof_ahas = sum(aha),
Aha_rate = Nbof_ahas/Nbof_participants,
Nbof_ahas_solvers = sum(solver*aha),
Aha_rate_solvers = Nbof_ahas_solvers / Nbof_solvers,
Avg_task_time = mean(task_time),
Avg_nbof_moves = mean(nbof_moves)
)
partic_groups <- arrange(partic_groups, factor(condition, levels = c("wlin", "wlout", "wnol", "wnolfs", "wnola", "moonsq", "wonly")))
partic_groups_rownames <- tibble::column_to_rownames(partic_groups, "condition")
# WLIN <- filter(participantdata, condition=="wlin")
# WLOUT <- filter(participantdata, condition=="wlout")
# WNOL <- filter(participantdata, condition=="wnol")
# WNOLFS <- filter(participantdata, condition=="wnolfs")
# WNOLA <- filter(participantdata, condition=="wnola")
# MOONSQ <- filter(participantdata, condition=="moonsq")
# WONLY <- filter(participantdata, condition=="wonly")
kable(partic_groups[,c(1, 2, 10, 5, 11, 12)],
digits = 3,
col.names = c("Condition", "Number of participants", "Aha rate of solvers", "Failure rate", "Avg task time", "Avg number of moves"))
# make this tables nicer: shorter headers, floating point numbers
missing <- (78 - partic_groups$Nbof_participants)
# Chunk 10: Plot
if (1==0){
participantdata_inc2 <- arrange(participantdata_inc2, condition)
for (i in participantdata_inc2$index){
P <- filter(participantdata,index==i)
M <- filter(movedata, index==i)
plot(M$timestamp, M$match)
title(c(P$index, P$condition[], P$Solver))
}
}
# Color points by rule!
# What if no rule is TRUE? What is more than 1 rule is TRUE?
# Chunk 11: Fisher tests
barplot(partic_groups$Solution_rate, names.arg = partic_groups$condition, main="Solution rates")
# fisher.test(partic_groups2[c("wlin","wlout"), c("Nbof_solvers","Nbof_nonsolvers")])
# fisher.test(partic_groups2[c("wlout","wnol"), c("Nbof_solvers","Nbof_nonsolvers")])
# fisher.test(partic_groups2[c("wnolfs","wnola"), c("Nbof_solvers","Nbof_nonsolvers")])
# fisher.test(partic_groups2[c("moonsq","wnola"), c("Nbof_solvers","Nbof_nonsolvers")])
# Chunk 12: Fisher tests 2
barplot(partic_groups$Failure_rate, names.arg = partic_groups$condition, main="Failure rates")
# Chunk 13: Normality
#hist(participantdata_inc2$task_time)
# wlin_time <- participantdata_inc2 %>% filter(condition=="wlin") %>% select(task_time)
# wlin_time <- matrix(wlin_time[,1])
#
# wlout_time <- participantdata_inc2 %>% filter(condition=="wlout") %>% select(task_time)
# wlout_time <- matrix(wlout_time[,1])
#
#
#
# normality_wlin <- ks.test(
#   participantdata_inc2 %>% filter(condition=="wlin") %>% select(task_time),
#   pnorm, alternative="two.sided", exact=NULL)
# normality_wlout <- ks.test(
#   participantdata_inc2 %>% filter(condition=="wlout") %>% select(task_time),
#   pnorm, alternative="two.sided", exact=NULL)
#
# normality_wlin
# normality_wlout
# Chunk 14: ANOVA or Wilcoxon
# greenhouse-geisser correction: robust also for non-normally distributed data
#participantdata_inc2$condition <- factor(participantdata_inc2$condition , levels=c("wlin", "wlout", "wnol", "wnolfs", "wnola", "moonsq", "wonly"))
boxplot(task_time ~ condition,
participantdata_inc2,
ylab="Task time")
# if (normality_wlin$p.value > 0.05 && normality_wlout$p.value > 0.05) {
#   stati <- t.test(wlin_time, wlout_time,
#                   alternative="two.sided", paired=FALSE, var.equal=FALSE, conf.level=0.95)
#   } else {
#     stati <- wilcox.test(wlin_time, wlout_time,
#                          alternative="two.sided", paired=FALSE, exact=NULL, correct=TRUE, conf.int=TRUE, conf.level=0.95) # two sample Wilcoxon test is the same as the Mann-Whitney test
#   }
#
#
# stati
# Chunk 15: Aha-ratings
barplot(partic_groups$Aha_rate_solvers, names.arg = partic_groups$condition, main="Aha rate of solvers")
